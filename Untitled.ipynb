{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from models.layers import *\n",
    "import torch\n",
    "input = torch.randn([4,3,224,224])\n",
    "emb1 = PatchEmbed()\n",
    "emb1(input).size()\n",
    "emb2= ConvolutionalEmbed()\n",
    "emb2(input).size()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\n",
    "from thop import profile\n",
    "import warnings\n",
    "import models\n",
    "models.list_models()\n",
    "warnings.filterwarnings('ignore')\n",
    "input=torch.randn([1,3,224,224])\n",
    "\n",
    "model = models.SCgmlp_S7()\n",
    "flop,para = profile(model,inputs=(input,))\n",
    "print('with input size {}, model has para numbers {} and flops {} '.format(input.size(),para,flop))\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch \n",
    "ck = torch.load('/data/zhicai/ckpts/Mgmlp/train/20210923-125519-nest_gmlp_s-224/last.pth.tar')\n",
    "print(ck[\"state_dict_ema\"].keys())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import models\n",
    "M3gmlp = models.create_model('M3gmlp_s16_224')\n",
    "gmlp = models.create_model('gmlp_s16_224')\n",
    "state_dict = gmlp.state_dict()\n",
    "for name,para in M3gmlp.named_parameters():\n",
    "    if name in state_dict.keys():\n",
    "        para.requires_grad = False"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\n",
    "ckpt = torch.load('/home/zhicai/Mgmlp/output/train/20210725-171200-SCG3gmlp_ti16_224-224/checkpoint-129.pth.tar')\n",
    "to_kw=[]\n",
    "to_vw=[]\n",
    "to_kb=[]\n",
    "to_vb=[]\n",
    "for k,v in ckpt['state_dict_ema'].items():\n",
    "    if \"gate.proj_list\" in k and 'weight' in k:\n",
    "        to_kw.append(k)\n",
    "        to_vw.append(v)\n",
    "    if \"gate.proj_list\" in k and 'bias' in k:\n",
    "        to_kb.append(k)\n",
    "        to_vb.append(v)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(50, 50),tight_layout=True)\n",
    "for i, idx in enumerate(range(6,0,-1)):\n",
    "    ax1 = fig.add_subplot(3,2,i+1)\n",
    "    ax1.imshow(to_vw[-idx].cpu())\n",
    "    # ax1.axis('off')\n",
    "fig.savefig('save_img.jpg', facecolor='grey', edgecolor='red')\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\n",
    "ckpt = torch.load('/home/zhicai/Mgmlp/output/train/20210727-073338-SCG3gmlp_s16_224-224/checkpoint-129.pth.tar')\n",
    "out = []\n",
    "for k,v in ckpt['state_dict_ema'].items():\n",
    "    print(k,' ', v.size())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\n",
    "ckpt = torch.load('/home/zhicai/Mgmlp/output/train/20210727-162220-gmlp_s16_224-224/checkpoint-118.pth.tar')\n",
    "out = []\n",
    "for k,v in ckpt['state_dict_ema'].items():\n",
    "    print(k,' ', v.size())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import csv\n",
    "def get_data(csv_file):\n",
    "    with open(csv_file +'/summary.csv','r') as f:\n",
    "            row = csv.reader(f, delimiter = ',')\n",
    "            next(row)  #读取首行\n",
    "            epoch = []\n",
    "            train_loss = []\n",
    "            eval_loss = []\n",
    "            ac1 = []\n",
    "            for i, t_l,e_l,acc,_  in row:\n",
    "                epoch.append(int(i))\n",
    "                train_loss.append(float(t_l))\n",
    "                eval_loss.append(float(e_l))\n",
    "                ac1.append(float(acc))\n",
    "    return epoch,train_loss,eval_loss,ac1\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from matplotlib import pyplot as plt\n",
    "f1= '/home/zhicai/Mgmlp/output/train/79.44-SCG3gmlp_convstem_s16_224_2-224'\n",
    "f2 = '/home/zhicai/Mgmlp/output/train/78.79-M3gmlp_s16_224-224'\n",
    "# f3 = '/home/zhicai/Mgmlp/output/train/83.64-SCG3gmlp_convstem_s16_224_2-224_no gamma_half_data'\n",
    "epoch1,train_loss1,eval_loss1,acc1 = get_data(f1)\n",
    "epoch2,train_loss2,eval_loss2,acc2 = get_data(f2)\n",
    "# epoch3,train_loss3,_,acc3 = get_data(f3)\n",
    "\n",
    "plt.title('eval loss figure')\n",
    "plt.xlabel(\"epoch\") \n",
    "plt.ylabel(\"eval loss\") \n",
    "plt.plot(epoch1,eval_loss1,  c=\"#9966ff\", label=\"M3gmlp\")\n",
    "plt.plot(epoch2,eval_loss2,  c=\"#00BB00\", label=\"SCG3gmlp_convstem_gamma4_S\")\n",
    "# plt.plot(epoch3,acc3,   c=\"#EA0000\", label=\"SCG3gmlp_convstem_S\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import torch\n",
    "path = '/home/zhicai/Mgmlp/checkpoint-215.pth.tar'\n",
    "ckpt = torch.load(path)\n",
    "to_kw=[]\n",
    "to_vw=[]\n",
    "to_kb=[]\n",
    "to_vb=[]\n",
    "to_kp=[]\n",
    "to_vp=[]\n",
    "to_kidx=[]\n",
    "to_vidx=[]\n",
    "\n",
    "for k,v in ckpt['state_dict_ema'].items():\n",
    "    if \"gate_unit.proj\" in k and 'weight' in k:\n",
    "        to_kw.append(k)\n",
    "        to_vw.append(v.cpu())\n",
    "    if \"gate_unit.proj\" in k and 'bias' in k:\n",
    "        to_kb.append(k)\n",
    "        to_vb.append(v.cpu())\n",
    "    if 'relative_position_bias_table' in k:\n",
    "        to_kp.append(k)\n",
    "        to_vp.append(v.cpu())\n",
    "    if 'relative_position_index' in k:\n",
    "        to_kidx.append(k)\n",
    "        to_vidx.append(v.cpu())\n",
    "print(f\"number of figures is {len(to_kw)}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "number of figures is 24\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "import math\n",
    "bias_map =[]\n",
    "for vp in to_vp:\n",
    "    h,w = to_vidx[0].size()\n",
    "    bias_map.append(vp[to_vidx[0].view(-1)].view(h,w))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "bias_map[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-1.8594e+00,  2.6169e-02,  5.7350e-02,  ...,  5.4230e-03,\n",
       "          4.2089e-03,  6.5682e-03],\n",
       "        [ 3.5696e-02, -1.8594e+00,  2.6169e-02,  ..., -4.0690e-04,\n",
       "          5.4230e-03,  4.2089e-03],\n",
       "        [ 5.3676e-02,  3.5696e-02, -1.8594e+00,  ...,  2.1450e-03,\n",
       "         -4.0690e-04,  5.4230e-03],\n",
       "        ...,\n",
       "        [ 1.4802e-03, -2.2688e-03,  3.3597e-03,  ..., -1.8594e+00,\n",
       "          2.6169e-02,  5.7350e-02],\n",
       "        [-3.6979e-03,  1.4802e-03, -2.2688e-03,  ...,  3.5696e-02,\n",
       "         -1.8594e+00,  2.6169e-02],\n",
       "        [ 4.7923e-03, -3.6979e-03,  1.4802e-03,  ...,  5.3676e-02,\n",
       "          3.5696e-02, -1.8594e+00]])"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(50, 50),tight_layout=True)\n",
    "for i, idx in enumerate(range(0,20,1)):\n",
    "    ax1 = fig.add_subplot(10,2,i+1)\n",
    "    ax1.imshow(to_vw[idx].cpu())\n",
    "    # ax1.axis('off')\n",
    "fig.savefig('save_img.jpg', facecolor='grey', edgecolor='red')\n",
    "plt.show()\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "def getdata(path):\n",
    "    acc=[]\n",
    "    loss_train=[]\n",
    "    with open(path,'r') as f:\n",
    "        cr = f.readlines()\n",
    "        for idx, row in enumerate(cr):\n",
    "            if idx==0:\n",
    "                continue\n",
    "            row = row.strip().split(',')\n",
    "            acc.append(float((row[3])))\n",
    "            loss_train.append(float(row[1]))\n",
    "    return acc,loss_train\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "acc1,_=getdata('/home/zhicai/Mgmlp/output/train/20210725-152757-gmlp_ti16_224-224/summary.csv')\n",
    "acc2,_=getdata('/home/zhicai/Mgmlp/output/train/20210725-165048-M3gmlp_ti16_224-224/summary.csv')\n",
    "acc3,_ =getdata('/home/zhicai/Mgmlp/output/train/20210725-171200-SCG3gmlp_ti16_224-224/summary.csv')\n",
    "import numpy as np\n",
    "plt.figure(figsize=(10, 8.5))\n",
    "plt.plot(acc1,label='gmlp-ti_baseline')\n",
    "plt.plot(acc2,label='M3gmlp-ti')\n",
    "plt.plot(acc3,label='SCG3gmlp-ti')\n",
    "plt.ylabel('ACC1')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "plt.figure(figsize=(10, 8.5))\n",
    "plt.plot(acc1,label='gmlp-ti_baseline')\n",
    "plt.plot(acc2,label='M3gmlp-ti')\n",
    "plt.plot(acc3,label='SCG3gmlp-ti')\n",
    "plt.ylabel('ACC1')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from models.splat import *\n",
    "import torch\n",
    "from thop import profile\n",
    "import warnings\n",
    "import models\n",
    "warnings.filterwarnings('ignore')\n",
    "input =  torch.randn(4,256,224,224)\n",
    "model = SplAtConv2d(256,256,1,stride=1,padding=0,groups=1,radix=4)\n",
    "flop,para = profile(model,inputs=(input,))\n",
    "out = model(input)\n",
    "print('with input size {}, model has para numbers {} and flops {} '.format(input.size(),para,flop))\n",
    "out.size()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from models.splat import *\n",
    "import torch\n",
    "from thop import profile\n",
    "model2 =conv2(256,256,1,stride=1,padding=0)\n",
    "input =  torch.randn(4,256,224,224)\n",
    "flop,para = profile(model2,inputs=(input,))\n",
    "print('with input size {}, model has para numbers {} and flops {} '.format(input.size(),para,flop))\n",
    "out = model2(input)\n",
    "out.size()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.3 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "interpreter": {
   "hash": "451ea3fe770d0dbd78d474f840636a3609bb179e9d011ae4388eaee9f8de5df9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}